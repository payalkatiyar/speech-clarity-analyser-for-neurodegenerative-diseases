Week 2 -

Dataset Preparation -
Steps-
1. using the raw data structure als-f/fc/m/mc-f##/fc##/m##/mc##-session#-audio##.wav, use project folder to split datasets as given in the commands-
mkdir -p data/audio/train/{normal,dysarthric}/{headmic,arraymic}
mkdir -p data/audio/test/{normal,dysarthric}/headmic

2. run prepare_dataset.py only once, if needed to run again remove the whole data folder again make empty directories using commands in step 1 then run prepare_dataset.py again.

Datasets in the structure data-audio-train/test-dysarthric/normal-arraymic/headmic.
"prepare_dataset.py" uses als folder which contains raw data and splits them in a 70:30 ratio of using the audio samples from a headmic(clearer closer audio) and arraymic(distant and vague audio).
The 70:30 split will help in training the model to be more perceptible to noisy audio inputs without taking noise as a parameter for evaluation of clarity scores.
 

Week 2 - split the refined dataset efficiently further to be used in training the model optimally.

Week 3 -
do not rerun - clean_audio.py , audio_processing.py (removes silent files, and trims silences)
